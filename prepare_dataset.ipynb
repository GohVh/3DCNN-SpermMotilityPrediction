{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'stride 1/10'\n",
    "'8frames, 34batch, 272 dense optical flow frames'\n",
    "'11frames, 34batch, 374 dense optical flow frames'\n",
    "'14frames, 34batch, 476 dense optical flow frames'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Params to Generate Dense optical flow frames'\n",
    "videofolder = r'/home/gvh/Desktop/videos/'\n",
    "denseoutputfolder = r'/home/gvh/Desktop/stride1/denseoptflow-11f374/'\n",
    "d1_stridenum = 1\n",
    "d1_extractnum = 374\n",
    "d1_imgsize = 144\n",
    "\"\"\"\n",
    "Dataset types generation attributes:\n",
    "A. \n",
    "8 frames per sample, 34 samples from 1 video (1 batch 34 samples), stride=1\n",
    "d1_stridenum = 1, d1_extractnum = 272, d1_imgsize = 144\n",
    "\n",
    "B. \n",
    "11 frames per sample, 34 samples from 1 video (1 batch 34 samples), stride=1\n",
    "d1_stridenum = 1, d1_extractnum = 374, d1_imgsize = 144\n",
    "\n",
    "C. \n",
    "14 frames per sample, 34 samples from 1 video (1 batch 34 samples), stride=1\n",
    "d1_stridenum = 1, d1_extractnum = 476, d1_imgsize = 144\n",
    "\n",
    "D. \n",
    "8 frames per sample, 34 samples from 1 video (1 batch 34 samples), stride=10\n",
    "d1_stridenum = 10, d1_extractnum = 272, d1_imgsize = 144\n",
    "\n",
    "E. \n",
    "11 frames per sample, 34 samples from 1 video (1 batch 34 samples), stride=10\n",
    "d1_stridenum = 10, d1_extractnum = 374, d1_imgsize = 144\n",
    "\n",
    "F. \n",
    "14 frames per sample, 34 samples from 1 video (1 batch 34 samples), stride=10\n",
    "d1_stridenum = 10, d1_extractnum = 476, d1_imgsize = 144\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'generate dense opt image'\n",
    "d1gen_frame(videofolder, denseoutputfolder, d1_stridenum, d1_extractnum, d1_imgsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Params to stack D1'\n",
    "denseextractfolder = r'/home/gvh/Desktop/stride1/denseoptflow-11f374/'\n",
    "stackedfolder = r'/home/gvh/Desktop/stride1/11f34b-data1/'\n",
    "stackframe_num = 11\n",
    "batchnum = 34\n",
    "h = d1_imgsize\n",
    "w = d1_imgsize\n",
    "\n",
    "\"\"\"\n",
    "Dataset types generation attributes:\n",
    "A, D --> stackframe_num = 8\n",
    "B, E --> stackframe_num = 11\n",
    "C, F --> stackframe_num = 14\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack(denseextractfolder, stackedfolder, stackframe_num, batchnum, h,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Optional, to check if stacking methods are correct'\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "\n",
    "# imgadd1 = r'/home/gvh/Desktop/eg/denseopt-s1-11f374/7/0.png'\n",
    "# imgadd2 = r'/home/gvh/Desktop/eg/denseopt-s1-11f374/47/150.png'\n",
    "# imgadd3 = r'/home/gvh/Desktop/eg/denseopt-s1-11f374/82/372.png'\n",
    "\n",
    "# # npyadd = r\"C:\\Users\\User\\Desktop\\3DCNN\\3 FOLD VALIDATION\\pytorch\\obsolete\\obsolete trial copy\\data1trial\\6_7.npy\"\n",
    "\n",
    "# npyadd1 = r'/home/gvh/Desktop/eg/11f34b-data1/7_0.npy'\n",
    "# npyadd2 = r'/home/gvh/Desktop/eg/11f34b-data1/47_13.npy'\n",
    "# npyadd3 = r'/home/gvh/Desktop/eg/11f34b-data1/82_33.npy'\n",
    "\n",
    "# img1 = cv2.imread(imgadd1)\n",
    "# img2 = cv2.imread(imgadd2)\n",
    "# img3 = cv2.imread(imgadd3)\n",
    "\n",
    "# # npy1 = np.load(npyadd)\n",
    "\n",
    "# npy1 = np.load(npyadd1)\n",
    "# npy2 = np.load(npyadd2)\n",
    "# npy3 = np.load(npyadd3)\n",
    "\n",
    "# print(img1[:,:,0])\n",
    "# print(img1.shape)\n",
    "# print('-------')\n",
    "# print(npy1[0,:,:,0])\n",
    "# print(np.shape(npy1))\n",
    "# print('*****************************************')\n",
    "# print(img2[:,:,1])\n",
    "# print('-------')\n",
    "# print(npy2[1,:,:,7])\n",
    "# print('*****************************************')\n",
    "# print(img3[:,:,2])\n",
    "# print('-------')\n",
    "# print(npy3[2,:,:,9])\n",
    "# print('*****************************************')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepcv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13 (default, Oct 19 2022, 10:19:43) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "bc8728ca46fe0e46829d869d02c49a317711a0a5ed1f065b44257a00e89bb2e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
